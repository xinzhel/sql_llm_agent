{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.323\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import langchain\n",
    "print(langchain.__version__)\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Prompts #####\n",
    "constraints = {\n",
    "    \"short\": \"\"\"Short and Clear: Keep your queries short and straightforward. Cut down on words and skip parts of speech that aren't crucial, such as conjunctions and articles. It's okay to use fragmented phrases as long as they still convey the full meaning.\"\"\",\n",
    "    \"long\": \"\"\"Complex Sentence Structure: Ensure your queries are always in complete sentences. Opt for longer, more complex sentence structures, incorporating elements of speech like conjunctions and articles for fuller expression.\"\"\",\n",
    "    \"interrogative\": \"\"\"Interrogative Form: Queries should take the form of direct questions, using interrogative words like \"who,\" \"what,\" \"where,\" \"when,\" \"why,\" and \"how.\" This form directly signals a request for information.\"\"\",\n",
    "    \"directives\": \"\"\"Directives: Queries should be framed as directives or commands, such as \"Tell me about…\" or \"Show me…\". These are less interrogative but still clearly indicate a request for information.\"\"\",\n",
    "    \"formal\": \"\"\"Formal: Queries should be written in a formal tone, using proper grammar and avoiding slang or colloquialisms. This is the most appropriate tone for professional settings.\"\"\",\n",
    "    \"casual\": \"\"\"Formal: Queries should be written in a casual tone, using informal grammar and colloquialisms. This is the most appropriate tone for casual settings.\"\"\",\n",
    "}\n",
    "\n",
    "\n",
    "task_description_ptt = \"\"\"Convert the given SQL query with placeholders into human understandable text. Each placeholder is a combination of table and column names, formatted as \"[Table.Column]\", like \"[User.Name]\". \n",
    "\n",
    "The generation step should:\n",
    "* Keep the original placeholders from the SQL queries intact.\n",
    "* Create text that can be comprehended by people who have no knowledge of relational databases.\n",
    "{short_or_long}{interrogative_or_directives}\n",
    "* Generate three translations of text that are diverse in phrasing and syntax, each in a separate line \n",
    "* Not include any other text in your response.\n",
    "\"\"\"\n",
    "list_item_prefix = \"\\n* \"\n",
    "task_description_pt = PromptTemplate(input_variables=['short_or_long', 'interrogative_or_directives'], template=task_description_ptt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of templates for each table:\n",
      "Project 7\n",
      "Capability 2\n",
      "Employee 12\n",
      "Company 6\n",
      "Total number of templates:  27\n"
     ]
    }
   ],
   "source": [
    "from utils import read_template_from_txt_files\n",
    "all_templates = read_template_from_txt_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Project': [], 'Capability': [], 'Employee': [], 'Company': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table: Project, template: 0\n",
      "table: Project, template: 1\n",
      "table: Project, template: 2\n",
      "table: Project, template: 3\n",
      "table: Project, template: 4\n",
      "table: Project, template: 5\n",
      "table: Project, template: 6\n",
      "table: Capability, template: 0\n",
      "table: Capability, template: 1\n",
      "table: Employee, template: 0\n",
      "table: Employee, template: 1\n",
      "table: Employee, template: 2\n",
      "table: Employee, template: 3\n",
      "table: Employee, template: 4\n",
      "table: Employee, template: 5\n",
      "table: Employee, template: 6\n",
      "table: Employee, template: 7\n",
      "table: Employee, template: 8\n",
      "table: Employee, template: 9\n",
      "table: Employee, template: 10\n",
      "table: Employee, template: 11\n",
      "table: Company, template: 0\n",
      "table: Company, template: 1\n",
      "table: Company, template: 2\n",
      "table: Company, template: 3\n",
      "table: Company, template: 4\n",
      "table: Company, template: 5\n"
     ]
    }
   ],
   "source": [
    "def generate(sys_msg, usr_msg, model_name = \"gpt4-short\"):\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        deployment_id=model_name,\n",
    "        messages=[{\"role\": \"system\", \"content\": sys_msg}, \n",
    "               {\"role\": \"user\", \"content\": usr_msg}],\n",
    "        temperature=1\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def save_templates_to_text(templates, directory=\"./templates/text/\"):\n",
    "    filename = f\"templates_to_be_extracted.txt\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.write(templates)\n",
    "\n",
    "sys_msg = task_description_pt.format(short_or_long=list_item_prefix+ constraints['short'], interrogative_or_directives=\"\")\n",
    "# results are stored in a dictionary with the following structure: \n",
    "# { table1: {\"sql_template1\": [text1, text2], \n",
    "#            \"sql_template2\": [text1, text2]}, \n",
    "#  {table2: {\"sql_template1\": [text1, text2], \n",
    "#             \"sql_template2\": [text1, text2}, \n",
    "# ...\n",
    "# }\n",
    "results = {table_name: None for table_name in all_templates.keys()}\n",
    "for table_name, sql_templates in all_templates.items():\n",
    "    texts_for_templates = {}\n",
    "    for i, sql_template in enumerate(sql_templates):\n",
    "        response = generate(sys_msg, sql_template)\n",
    "        texts_for_templates[sql_template] = [x for x in response.choices[0].message.content.split(\"\\n\") if x]\n",
    "        print(f\"table: {table_name}, template: {i}\")\n",
    "    results[table_name] = texts_for_templates\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to json file\n",
    "import json\n",
    "with open('templates/text/templates_for_each_table.json', 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
